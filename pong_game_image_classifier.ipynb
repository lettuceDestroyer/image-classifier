{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "The following jupyter notebook was created using the following two websites:\n",
        "- https://rumn.medium.com/custom-pytorch-image-classifier-from-scratch-d7b3c50f9fbe\n",
        "- https://github.com/lettuceDestroyer/image_classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8rlt9KQ7491"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "Ty-et5bEy4Ij"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "from torchvision.io import read_image, ImageReadMode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "ROOT_FOLDER_PATH = \"C:\\\\Users\\\\tobil\\\\Downloads\\\\image-taker\"\n",
        "NUMBER_OF_LABELS = 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxJc0x0UA6jF"
      },
      "source": [
        "# Datasets and Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "68jc0MMp-RRO"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "heuGVU4p-Ufw"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform):\n",
        "        self.transform = transform\n",
        "        \n",
        "        self.image_paths = []\n",
        "        for ext in ['png', 'jpg']:\n",
        "            self.image_paths += glob.glob(os.path.join(root_dir, '*', f'*.{ext}'))\n",
        "        class_set = set()\n",
        "        for path in self.image_paths:\n",
        "            class_set.add(os.path.basename(os.path.dirname(path)))\n",
        "        self.class_lbl = { cls: i for i, cls in enumerate(sorted(list(class_set)))}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = read_image(self.image_paths[idx], ImageReadMode.RGB).float()\n",
        "        cls = os.path.basename(os.path.dirname(self.image_paths[idx]))\n",
        "        label = self.class_lbl[cls]\n",
        "\n",
        "        return self.transform(img), torch.tensor(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "5PoRI8oY-4fW"
      },
      "outputs": [],
      "source": [
        "#dataset = CustomDataset(ROOT_FOLDER_PATH, transform)\n",
        "dataset = CustomDataset(ROOT_FOLDER_PATH, transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "gcHVJ-D1A4Ns"
      },
      "outputs": [],
      "source": [
        "splits = [0.8, 0.1, 0.1]\n",
        "split_sizes = []\n",
        "for sp in splits[:-1]:\n",
        "    split_sizes.append(int(sp * len(dataset)))\n",
        "split_sizes.append(len(dataset) - sum(split_sizes))\n",
        "\n",
        "train_set, test_set, val_set = torch.utils.data.random_split(dataset, split_sizes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "jUL0V1IuBLpA"
      },
      "outputs": [],
      "source": [
        "dataloaders = {\n",
        "    \"train\": DataLoader(train_set, batch_size=8, shuffle=True),\n",
        "    \"test\": DataLoader(test_set, batch_size=8, shuffle=False),\n",
        "    \"val\": DataLoader(val_set, batch_size=8, shuffle=False)\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uREM4wMyBTEO"
      },
      "source": [
        "# Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "1_pmA8HOBfmO"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "Jh3pnc2qBQxc"
      },
      "outputs": [],
      "source": [
        "model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
        "model.fc = torch.nn.Linear(2048, NUMBER_OF_LABELS)\n",
        "model.to(device)\n",
        "pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "sL-H5jWDBljY"
      },
      "outputs": [],
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_kBI1lPCmWk"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "20LhennnDQGc"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 10\n",
        "NUM_CLASSES = len(dataset.class_lbl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "NwprpAdZI-0N"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'0': 0, '1': 1, '2': 2, '3': 3, '4': 4}"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.class_lbl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "mNMGTlbdCl6A"
      },
      "outputs": [],
      "source": [
        "metrics = {\n",
        "    'train': {'loss': [], 'accuracy': []},\n",
        "    'val': {'loss': [], 'accuracy': []},\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Mr9KYOyCu7V"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0\n",
            "-------- train --------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/235 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 235/235 [03:52<00:00,  1.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.16536697372596, Accuracy: 0.951063829787234\n",
            "\n",
            "-------- val --------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:11<00:00,  2.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.027967976910683017, Accuracy: 0.9958333333333333\n",
            "\n",
            "Epoch 1\n",
            "-------- train --------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 235/235 [02:41<00:00,  1.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.02039459517220669, Accuracy: 0.9962765957446809\n",
            "\n",
            "-------- val --------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:06<00:00,  4.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0031370956741739063, Accuracy: 1.0\n",
            "\n",
            "Epoch 2\n",
            "-------- train --------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 235/235 [02:15<00:00,  1.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.003807809290524443, Accuracy: 1.0\n",
            "\n",
            "-------- val --------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:06<00:00,  4.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0011924368731949168, Accuracy: 1.0\n",
            "\n",
            "Epoch 3\n",
            "-------- train --------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 235/235 [02:21<00:00,  1.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0024165184292484054, Accuracy: 1.0\n",
            "\n",
            "-------- val --------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:06<00:00,  4.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0014564336500673865, Accuracy: 1.0\n",
            "\n",
            "Epoch 4\n",
            "-------- train --------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 235/235 [02:16<00:00,  1.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.01637178419620428, Accuracy: 0.9946808510638298\n",
            "\n",
            "-------- val --------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:06<00:00,  4.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.004081093804173482, Accuracy: 1.0\n",
            "\n",
            "Epoch 5\n",
            "-------- train --------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 235/235 [02:44<00:00,  1.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.017130229577355265, Accuracy: 0.9957446808510638\n",
            "\n",
            "-------- val --------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:08<00:00,  3.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.043943894107360396, Accuracy: 0.9958333333333333\n",
            "\n",
            "Epoch 6\n",
            "-------- train --------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 235/235 [19:15<00:00,  4.92s/it]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.0313941594577974, Accuracy: 0.9909574468085106\n",
            "\n",
            "-------- val --------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:08<00:00,  3.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.001308706108344874, Accuracy: 1.0\n",
            "\n",
            "Epoch 7\n",
            "-------- train --------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 235/235 [02:56<00:00,  1.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.009299867067107078, Accuracy: 0.9984042553191489\n",
            "\n",
            "-------- val --------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:08<00:00,  3.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.002471204300915512, Accuracy: 1.0\n",
            "\n",
            "Epoch 8\n",
            "-------- train --------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 75%|███████▌  | 177/235 [02:06<00:35,  1.64it/s]"
          ]
        }
      ],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  ep_metrics = {\n",
        "    'train': {'loss': 0, 'accuracy': 0, 'count': 0},\n",
        "    'val': {'loss': 0, 'accuracy': 0, 'count': 0},\n",
        "  }\n",
        "\n",
        "  print(f'Epoch {epoch}')\n",
        "\n",
        "  for phase in ['train', 'val']:\n",
        "    print(f'-------- {phase} --------')\n",
        "    for images, labels in tqdm(dataloaders[phase]):\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      with torch.set_grad_enabled(phase == 'train'):\n",
        "        output = model(images.to(device))\n",
        "        ohe_label = torch.nn.functional.one_hot(labels,\n",
        "                                                num_classes=NUM_CLASSES)\n",
        "\n",
        "        loss = criterion(output, ohe_label.float().to(device))\n",
        "\n",
        "        correct_preds = labels.to(device) == torch.argmax(output, dim=1)\n",
        "        accuracy = (correct_preds).sum()/len(labels)\n",
        "\n",
        "      if phase == 'train':\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "      ep_metrics[phase]['loss'] += loss.item()\n",
        "      ep_metrics[phase]['accuracy'] += accuracy.item()\n",
        "      ep_metrics[phase]['count'] += 1\n",
        "  \n",
        "    ep_loss = ep_metrics[phase]['loss']/ep_metrics[phase]['count']\n",
        "    ep_accuracy = ep_metrics[phase]['accuracy']/ep_metrics[phase]['count']\n",
        "\n",
        "    print(f'Loss: {ep_loss}, Accuracy: {ep_accuracy}\\n')\n",
        "\n",
        "    metrics[phase]['loss'].append(ep_loss)\n",
        "    metrics[phase]['accuracy'].append(ep_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLe4JScQEDZ1"
      },
      "outputs": [],
      "source": [
        "for phase in metrics:\n",
        "    for metric in metrics[phase]:\n",
        "        metric_data = metrics[phase][metric]\n",
        "        plt.plot(range(len(metric_data)), metric_data)\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel(f'{phase} {metric}')\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6I1EvhfD4zr"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4Jlwl61D5yu"
      },
      "outputs": [],
      "source": [
        "preds = []\n",
        "actual = []\n",
        "\n",
        "tot_loss = tot_acc = count = 0\n",
        "\n",
        "for images, labels in tqdm(dataloaders['test']):\n",
        "    with torch.set_grad_enabled(False):\n",
        "        output = model(images.to(device))\n",
        "        ohe_label = torch.nn.functional.one_hot(labels, num_classes=NUM_CLASSES)\n",
        "        out_labels = torch.argmax(output, dim=1)\n",
        "\n",
        "\n",
        "        tot_loss += criterion(output, ohe_label.float().to(device))\n",
        "        tot_acc += (labels.to(device) == out_labels).sum()/len(labels)\n",
        "        count += 1\n",
        "\n",
        "    preds += out_labels.tolist()\n",
        "    actual += labels.tolist()\n",
        "\n",
        "print(f\"Test Loss: {tot_loss / count}, Test Accuracy: {tot_acc / count}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2KQbe_kEJ4F"
      },
      "outputs": [],
      "source": [
        "class_labels = sorted(dataset.class_lbl.keys())\n",
        "\n",
        "cm = confusion_matrix(actual, preds)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels)\n",
        "\n",
        "disp.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WftBoaKvGSlM"
      },
      "outputs": [],
      "source": [
        "cm_np = np.array(cm)\n",
        "stats = pd.DataFrame(index=class_labels)\n",
        "stats['Precision'] = [cm_np[i, i]/np.sum(cm_np[:, i]) for i in range(len(cm_np))]\n",
        "stats['Recall'] = [cm_np[i, i]/np.sum(cm_np[i, :]) for i in range(len(cm_np))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QaQ0gtnH6tN"
      },
      "outputs": [],
      "source": [
        "stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJR0MhKrH_Vc"
      },
      "outputs": [],
      "source": [
        "example_inputs = (torch.randn(1, 1, 32, 32),)\n",
        "onnx_program = torch.onnx.export(model, example_inputs, dynamo=True)\n",
        "onnx_program.save(os.path.join(ROOT_FOLDER_PATH, \"image_classifier_model.onnx\"))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyPRw8cNuTCU4eqsip+Ico7N",
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
