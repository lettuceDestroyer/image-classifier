{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "The following jupyter notebook was created using the following two websites:\n",
        "- https://rumn.medium.com/custom-pytorch-image-classifier-from-scratch-d7b3c50f9fbe\n",
        "- https://github.com/lettuceDestroyer/image_classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8rlt9KQ7491"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Ty-et5bEy4Ij"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "from torchvision.io import read_image, ImageReadMode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# The folder which contains the images\n",
        "ROOT_FOLDER_PATH: str = \"C:\\\\Users\\\\tobil\\\\Downloads\\\\image-taker\"\n",
        "# The number of labels\n",
        "NUMBER_OF_LABELS: int = 5\n",
        "# The name to be used when exporting the model\n",
        "MODEL_EXPORT_NAME: str = \"image_classifier_model\"\n",
        "# Whether or not the model should be exported\n",
        "SHOULD_EXPORT_MODEL: bool = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxJc0x0UA6jF"
      },
      "source": [
        "# Datasets and Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "68jc0MMp-RRO"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "heuGVU4p-Ufw"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform):\n",
        "        self.transform = transform\n",
        "        \n",
        "        self.image_paths = []\n",
        "        for ext in ['png', 'jpg']:\n",
        "            self.image_paths += glob.glob(os.path.join(root_dir, '*', f'*.{ext}'))\n",
        "        class_set = set()\n",
        "        for path in self.image_paths:\n",
        "            class_set.add(os.path.basename(os.path.dirname(path)))\n",
        "        self.class_lbl = { cls: i for i, cls in enumerate(sorted(list(class_set)))}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = read_image(self.image_paths[idx], ImageReadMode.RGB).float()\n",
        "        cls = os.path.basename(os.path.dirname(self.image_paths[idx]))\n",
        "        label = self.class_lbl[cls]\n",
        "\n",
        "        return self.transform(img), torch.tensor(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "5PoRI8oY-4fW"
      },
      "outputs": [],
      "source": [
        "#dataset = CustomDataset(ROOT_FOLDER_PATH, transform)\n",
        "dataset = CustomDataset(ROOT_FOLDER_PATH, transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "gcHVJ-D1A4Ns"
      },
      "outputs": [],
      "source": [
        "splits = [0.8, 0.1, 0.1]\n",
        "split_sizes = []\n",
        "for sp in splits[:-1]:\n",
        "    split_sizes.append(int(sp * len(dataset)))\n",
        "split_sizes.append(len(dataset) - sum(split_sizes))\n",
        "\n",
        "train_set, test_set, val_set = torch.utils.data.random_split(dataset, split_sizes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "jUL0V1IuBLpA"
      },
      "outputs": [],
      "source": [
        "dataloaders = {\n",
        "    \"train\": DataLoader(train_set, batch_size=8, shuffle=True),\n",
        "    \"test\": DataLoader(test_set, batch_size=8, shuffle=False),\n",
        "    \"val\": DataLoader(val_set, batch_size=8, shuffle=False)\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uREM4wMyBTEO"
      },
      "source": [
        "# Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "1_pmA8HOBfmO"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Jh3pnc2qBQxc"
      },
      "outputs": [],
      "source": [
        "model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
        "model.fc = torch.nn.Linear(2048, NUMBER_OF_LABELS)\n",
        "model.to(device)\n",
        "pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "sL-H5jWDBljY"
      },
      "outputs": [],
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_kBI1lPCmWk"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "20LhennnDQGc"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 10\n",
        "NUM_CLASSES = len(dataset.class_lbl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NwprpAdZI-0N"
      },
      "outputs": [],
      "source": [
        "dataset.class_lbl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "mNMGTlbdCl6A"
      },
      "outputs": [],
      "source": [
        "metrics = {\n",
        "    'train': {'loss': [], 'accuracy': []},\n",
        "    'val': {'loss': [], 'accuracy': []},\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Mr9KYOyCu7V"
      },
      "outputs": [],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  ep_metrics = {\n",
        "    'train': {'loss': 0, 'accuracy': 0, 'count': 0},\n",
        "    'val': {'loss': 0, 'accuracy': 0, 'count': 0},\n",
        "  }\n",
        "\n",
        "  print(f'Epoch {epoch}')\n",
        "\n",
        "  for phase in ['train', 'val']:\n",
        "    print(f'-------- {phase} --------')\n",
        "    for images, labels in tqdm(dataloaders[phase]):\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      with torch.set_grad_enabled(phase == 'train'):\n",
        "        output = model(images.to(device))\n",
        "        ohe_label = torch.nn.functional.one_hot(labels,\n",
        "                                                num_classes=NUM_CLASSES)\n",
        "\n",
        "        loss = criterion(output, ohe_label.float().to(device))\n",
        "\n",
        "        correct_preds = labels.to(device) == torch.argmax(output, dim=1)\n",
        "        accuracy = (correct_preds).sum()/len(labels)\n",
        "\n",
        "      if phase == 'train':\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "      ep_metrics[phase]['loss'] += loss.item()\n",
        "      ep_metrics[phase]['accuracy'] += accuracy.item()\n",
        "      ep_metrics[phase]['count'] += 1\n",
        "  \n",
        "    ep_loss = ep_metrics[phase]['loss']/ep_metrics[phase]['count']\n",
        "    ep_accuracy = ep_metrics[phase]['accuracy']/ep_metrics[phase]['count']\n",
        "\n",
        "    print(f'Loss: {ep_loss}, Accuracy: {ep_accuracy}\\n')\n",
        "\n",
        "    metrics[phase]['loss'].append(ep_loss)\n",
        "    metrics[phase]['accuracy'].append(ep_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLe4JScQEDZ1"
      },
      "outputs": [],
      "source": [
        "for phase in metrics:\n",
        "    for metric in metrics[phase]:\n",
        "        metric_data = metrics[phase][metric]\n",
        "        plt.plot(range(len(metric_data)), metric_data)\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel(f'{phase} {metric}')\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6I1EvhfD4zr"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4Jlwl61D5yu"
      },
      "outputs": [],
      "source": [
        "preds = []\n",
        "actual = []\n",
        "\n",
        "tot_loss = tot_acc = count = 0\n",
        "\n",
        "for images, labels in tqdm(dataloaders['test']):\n",
        "    with torch.set_grad_enabled(False):\n",
        "        output = model(images.to(device))\n",
        "        ohe_label = torch.nn.functional.one_hot(labels, num_classes=NUM_CLASSES)\n",
        "        out_labels = torch.argmax(output, dim=1)\n",
        "\n",
        "        tot_loss += criterion(output, ohe_label.float().to(device))\n",
        "        tot_acc += (labels.to(device) == out_labels).sum()/len(labels)\n",
        "        count += 1\n",
        "\n",
        "    preds += out_labels.tolist()\n",
        "    actual += labels.tolist()\n",
        "\n",
        "print(f\"Test Loss: {tot_loss / count}, Test Accuracy: {tot_acc / count}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2KQbe_kEJ4F"
      },
      "outputs": [],
      "source": [
        "class_labels = sorted(dataset.class_lbl.keys())\n",
        "\n",
        "cm = confusion_matrix(actual, preds)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels)\n",
        "\n",
        "disp.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WftBoaKvGSlM"
      },
      "outputs": [],
      "source": [
        "cm_np = np.array(cm)\n",
        "stats = pd.DataFrame(index=class_labels)\n",
        "stats['Precision'] = [cm_np[i, i]/np.sum(cm_np[:, i]) for i in range(len(cm_np))]\n",
        "stats['Recall'] = [cm_np[i, i]/np.sum(cm_np[i, :]) for i in range(len(cm_np))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QaQ0gtnH6tN"
      },
      "outputs": [],
      "source": [
        "stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Export"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJR0MhKrH_Vc"
      },
      "outputs": [],
      "source": [
        "# Export to TorchScrip\n",
        "if SHOULD_EXPORT_MODEL:\n",
        "    model_scripted = torch.jit.script(model)\n",
        "    model_scripted.save(os.path.join(os.getcwd(), f\"{MODEL_EXPORT_NAME}.pt\"))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyPRw8cNuTCU4eqsip+Ico7N",
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
